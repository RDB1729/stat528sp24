---
title: "Homework 1: coding basics, review questions, and reading quiz"
author: "your name"
date: "Due: 01/26 at 11:59 PM"
output: pdf_document
header-includes: 
 - \usepackage{amsthm}
 - \usepackage{amsmath}
 - \usepackage{amsfonts}
 - \usepackage{amscd}
 - \usepackage{amssymb}
 - \usepackage{natbib}
 - \usepackage{url}
---

\allowdisplaybreaks

\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Prob}{\mathbb{P}}
\newcommand{\E}{\mathrm{E}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\inner}[1]{\langle #1 \rangle}
\newcommand{\yobs}{y_{\text{obs}}}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


This assignment is meant to serve multiple objectives:

 - You will gain familiarity with R, RStudio, R Markdown, and GitHub
 - You will perform at least one iteration of the courses's data science inspired workflow
 - You will gain experience with typing mathematics
 - You will learn some \texttt{dplyr} and \texttt{ggplot2} basics

STAT 528 is a collaborative course environment, especially for assignments that involve coding, modeling, and/or data analysis. You are encouraged to ask for help from other students. Coding and data science work flow can be very tedious. Having someone else look over your work or answering a basic question can save you a lot of time. However, direct copying is not accepting. All final work must be your own.



***

## Mathematical review questions

\noindent{\bf Problem 1}: Prove that the Binomial distribution arises as a sum of $n$ iid Bernoulli trials each with success probability $p$. 

\vspace*{1cm}

\noindent{\bf Problem 2}: Let $l(\theta)$ denote a twice continuously differentiable log likelihood corresponding to an iid sample under density $f_\theta$ where $n$ is the sample size. The score function is defined as
$$
  u(\theta) = \frac{\partial l(\theta)}{\partial\theta},
$$
and the Fisher information matrix is defined as
$$
  I(\theta) = -\E\left(\frac{\partial^2 l(\theta)}{\partial \theta^2}\right),
$$
where the expectation is over the assumed distribution for the data when the parameter value is $\theta$. Prove that
$$
  \E(u(\theta)) = 0 \qquad \text{and} \qquad \Var(u(\theta)) = I(\theta).
$$


## Programming questions 



## Visualization questions 


## Reading question 







